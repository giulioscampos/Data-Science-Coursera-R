for (i in 1:10) {
ss <- sample(1:dim(ozone)[1],replace=T)
ozone0 <- ozone0[ss,]; ozone0 <- ozone0[order(ozone0$ozone),]
loess0 <- loess(temperature ~ ozone, data=ozone0, span=0.2)
ll[i,] <- predict(loess0, newdata=data.frame(ozone=1:155))
}
# predict temp as a function of ozone
ll <- matrix(NA, nrow=10, ncol=155)
for (i in 1:10) {
ss <- sample(1:dim(ozone)[1],replace=T)
ozone0 <- ozone[ss,]; ozone0 <- ozone0[order(ozone0$ozone),]
loess0 <- loess(temperature ~ ozone, data=ozone0, span=0.2)
ll[i,] <- predict(loess0, newdata=data.frame(ozone=1:155))
}
plot(ozone$ozone, ozone$temperature, pch=19, cex=0.5)
for(i in 1:10){lines(1:155, ll[i,], col="grey", lwd=2)}
for(i in 1:10){lines(1:155, ll[i,], col="grey", lwd=3)}
for(i in 1:10){lines(1:155, ll[i,], col="grey", lwd=1)}
plot(ozone$ozone, ozone$temperature, pch=19, cex=0.5)
for(i in 1:10){lines(1:155, ll[i,], col="grey", lwd=1)}
plot(ozone$ozone, ozone$temperature, pch=19, cex=0.5)
lines(1:155, apply(ll, 2, mean), col="red", lwd=2)
library(caret)
predictors = data.frame(ozone=ozone$ozone)
temperature = ozone$temperature
treebag <- bag(predictors, temperature, B=10, bagControl=bagControl(fit=ctreeBag$fit,
predict=ctreeBag$pred,
aggregate=ctreeBag$aggregate))
treebag <- bag(predictors, temperature, B=10, bagControl=bagControl(fit=ctreeBag$fit,predict=ctreeBag$pred,aggregate=ctreeBag$aggregate))
install.packages('party')
treebag <- bag(predictors, temperature, B=10, bagControl=bagControl(fit=ctreeBag$fit,predict=ctreeBag$pred,aggregate=ctreeBag$aggregate))
data(iris);
library(ggplot2)
names(iris)
inTrain <- createDataPartition(y=iris$Species, p=0.7, list=FALSE)
training <- iris[inTrain,]; testing <- iris[-inTrain,]
dim(training);dim(testing)
qplot(Petal.Width, Sepal.Width, colour=Species, data=training)
library(caret)
modFit <- train(Species ~ ., method="rf", prox=TRUE)
modFit
modFit <- train(Species ~ ., method="rf")
modFit
modFit <- train(Species ~ ., method="rf", prox=TRUE)
modFit
getTree(modFit$finalModel, k=2)
install.packages("tree")
getTree(modFit$finalModel, k=2)
irisP <- classCenter(training[,c(3, 4)], training$Species, modFit$finalModel$prox)
library('caret')
irisP <- classCenter(training[,c(3, 4)], training$Species, modFit$finalModel$prox)
irisP <- classCenter(training[,c(3, 4)], training$Species, modFit$finalModel$prox)
library(ggplot2)
irisP <- classCenter(training[,c(3, 4)], training$Species, modFit$finalModel$prox)
qplot(Petal.Width, Petal.Length, colour=predRight, data=testing, main="newdata Predictions")
pred <- predict(modFit, testing); testing$predRight <- pred==testing$Species
table(pred, testing$Species)
qplot(Petal.Width, Petal.Length, colour=predRight, data=testing, main="newdata Predictions")
# Boosting
library('ISLR')
library('ggplot2')
data(Wage)
summary(Wage)
Wage <- subset(Wage, select=-c(logwage))
inTrain <- createDataPartition(y=Wage$wage, p=0.7, list=FALSE)
training <- Wage[inTrain,]
testing <- Wage[-inTrain,]
dim(training);dim(testing)
library('caret')
data(Wage)
summary(Wage)
Wage <- subset(Wage, select=-c(logwage))
inTrain <- createDataPartition(y=Wage$wage, p=0.7, list=FALSE)
training <- Wage[inTrain,]
testing <- Wage[-inTrain,]
dim(training);dim(testing)
modFit <- train(wage, ., method="gbm", data=training, verbose=FALSE)
print(modFit)
qplot(predict(modFit, testing), wage, data=training)
librar('rpart')
# boosting with trees
modFit <- train(wage, ., method="gbm", data=training, verbose=FALSE)
print(modFit)
qplot(predict(modFit, testing), wage, data=training)
library('ISLR')
library('ggplot2')
library('caret')
data(Wage)
summary(Wage)
Wage <- subset(Wage, select=-c(logwage))
inTrain <- createDataPartition(y=Wage$wage, p=0.7, list=FALSE)
training <- Wage[inTrain,]
testing <- Wage[-inTrain,]
dim(training);dim(testing)
# boosting with trees
modFit <- train(wage, ., method="gbm", data=training, verbose=FALSE)
print(modFit)
qplot(predict(modFit, testing), wage, data=training)
library('ISLR')
library('ggplot2')
library('caret')
data(Wage)
summary(Wage)
wage <- subset(Wage, select=-c(logwage))
inTrain <- createDataPartition(y=Wage$wage, p=0.7, list=FALSE)
training <- Wage[inTrain,]
testing <- Wage[-inTrain,]
dim(training);dim(testing)
# boosting with trees
modFit <- train(wage, ., method="gbm", data=training, verbose=FALSE)
print(modFit)
qplot(predict(modFit, testing), wage, data=training)
modFit <- train(wage ~ ., method="gbm", data=training, verbose=FALSE)
modFit <- train(wage ~ ., method="gbm", data=training, verbose=FALSE)
install.packages('caret')
install.packages("caret")
modFit <- train(wage ~ ., method="gbm", data=training, verbose=FALSE)
print(modFit)
qplot(predict(modFit, testing), wage, data=training)
# Boosting
library('ISLR')
library('ggplot2')
library('caret')
data(Wage)
summary(Wage)
wage <- subset(Wage, select=-c(logwage))
inTrain <- createDataPartition(y=Wage$wage, p=0.7, list=FALSE)
training <- Wage[inTrain,]
testing <- Wage[-inTrain,]
dim(training);dim(testing)
# boosting with trees
modFit <- train(wage ~ ., method="gbm", data=training, verbose=FALSE)
qplot(predict(modFit, testing), wage, data=training)
modFit <- train(wage ~ ., method="gbm", data=training, verbose=FALSE)
print(modFit)
qplot(predict(modFit, testing), wage, data=training)
qplot(predict(modFit, testing), wage, data=testing)
library('ISLR')
library('ggplot2')
library('caret')
data(Wage)
summary(Wage)
Wage <- subset(Wage, select=-c(logwage))
inTrain <- createDataPartition(y=Wage$wage, p=0.7, list=FALSE)
training <- Wage[inTrain,]
testing <- Wage[-inTrain,]
dim(training);dim(testing)
# boosting with trees
modFit <- train(wage ~ ., method="gbm", data=training, verbose=FALSE)
print(modFit)
qplot(predict(modFit, testing), wage, data=training)
qplot(predict(modFit, testing), wage, data=testing)
data(iris)
library(ggplot2)
names(iris)
table(iris$Species)
names(iris)
inTrain <- createDataPartition(y=iris$Species, p=0.7, list=FALSE)
training <- iris[inTrain,];testing <- iris[-inTrain,]
dim(training);dim(testing)
modlda = train(Species ~ ., data=training, method="lda")
modnb = train(Species ~ ., data=training, method="nb")
modlda = train(Species ~ ., data=training, method="lda")
modnb = train(Species ~ ., data=training, method="nb")
plda = predict(modlda, testing); pnb = predict(modnb, testing)
table(plda, pnb)
install.packages('AppliedPredictiveModeling')
install.packages('ElemStatLearn')
install.packages('pgmm')
install.packages('rpart')
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
inTrain <- createDataPartition(y=segmentationOriginal$Case, p=0.7, list = FALSE)
inTrain <- createDataPartition(y=segmentationOriginal$Case, p=0.7, list = FALSE)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
set.seed(125)
modFit <- train(Case ~ ., method="rpart", data=training)
modFit$finalModel
plot(modFit$finalModel)
plot(modFit$finalModel, uniform=TRUE, main="Classification Tree")
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
segmentationOriginal$Case
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
plot(modFit$finalModel, uniform=TRUE, main="Classification Tree")
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
print(modFit$finalModel)
segmentationOriginal$KurtIntenCh1
segmentationOriginal$Case
names(segmentationOriginal)
table(segmentationOriginal$TotalIntenCh4)
predict(modFit, newdata=testing)
inTrain <- data$Case == "Train"
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
set.seed(125)
modFit <- train(Case ~ ., method="rpart", data=training)
print(modFit$finalModel)
plot(modFit$finalModel, uniform=TRUE, main="Classification Tree")
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
modFit <- train(Class ~ ., method="rpart", data=training)
print(modFit$finalModel)
plot(modFit$finalModel, uniform=TRUE, main="Classification Tree")
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
library(rattle)
fancyRpartPlot(modFit$finalModel)
install.packages('rpart')
install.packages('rpart.plot')
library(rattle)
fancyRpartPlot(modFit$finalModel)
set.seed(125)
modFit <- train(Class ~ ., method="rpart", data=training)
print(modFit$finalModel)
plot(modFit$finalModel, uniform=TRUE, main="Classification Tree")
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
library(pgmm)
data(olive)
olive = olive[,-1]
newdata = as.data.frame(t(colMeans(olive)))
newdata
?t
colMeans(olive)
newdata
treeModel <- train(Area ~ ., data=olive, method="rpart2")
treeModel
predict(modFit, newdata=newdata)
predict(treeModel, newdata=newdata)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
?SAheart
modFit <- train(chd ~ age alcohol obesity tobacco typea ldl, method="rpart", data=trainSA)
modFit <- train(chd ~ age, alcohol, obesity, tobacco, typea, ldl, method="rpart", data=trainSA)
modFit <- train(chd ~ c(age, alcohol, obesity, tobacco, typea, ldl), method="rpart", data=trainSA)
modFit <- train(chd ~ age alcohol obesity tobacco typea ldl, method="rpart", data=trainSA)
modFit <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, method="glm", data=trainSA, family="binamial")
modFit <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, method="glm", data=trainSA, family="binomial")
modFit <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, method="glm", data=trainSA, family="binomial")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
modFit <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, method="glm", data=trainSA, family="binomial")
modFit$finalModel
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
predict(modFit$finalModel, testSA)
sapply(missClass, predict(modFit$finalModel, testSA))
sapply(predict(modFit$finalModel, testSA), missClass)
logitModel <- train(chd ~ age + alcohol + obesity + tobacco +
typea + ldl, data=trainSA, method="glm",
family="binomial")
logitModel
missClass <- function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
predictTrain <- predict(logitModel, trainSA)
predictTest <- predict(logitModel, testSA)
missClass(trainSA$chd, predictTrain) # 0.2727273
missClass(testSA$chd, predictTest) # 0.3116883
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
head(vowel.train)
head(vowel.test)
dim(vowel.train) # 528  11
dim(vowel.test) # 462  11
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
modelRf <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
order(varImp(modelRf), decreasing=T)
install.packages('randomForest')
install.packages('randomForest')
modelRf <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
order(varImp(modelRf), decreasing=T)
library('randomForest')
modelRf <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
order(varImp(modelRf), decreasing=T)
install.packages('AppliedPredictiveModeling')
install.packages('caret')
install.packages('ElemStatLearn')
install.packages('pgmm')
install.packages("caret")
install.packages("caret")
install.packages("caret")
library('AppliedPredictiveModeling')
library('caret')
library('ElemStatLearn')
library('pgmm')
library('rpart')
library('gbm')
library('lubritate')
library('forecast')
library('e1071')
install.packages("lubritate")
install.packages("forecast")
install.packages("1071")
install.packages("e1071")
install.packages("e1071")
library('lubritate')
library('forecast')
library('e1071')
install.packages("lubritate")
R.version
if(!require(installr)) {
install.packages("installr"); require(installr)}
updateR()
R.version
cars
library(caret)
library(randomForest)
library(dplyr)
?caret
training <- read.csv("./data/pml-training.csv")
training <- read.csv("data/pml-training.csv")
setwd("C:/Users/johnecon/Projects/datasciencecoursera/Practical Machine Learning/assignment/")
training <- read.csv("./data/pml-training.csv")
testing <- read.csv("./data/pml-testing.csv")
dim(training)
dim(testing)
setwd("C:/Users/johnecon/Projects/datasciencecoursera/Practical Machine Learning/assignment/")
pml_data <- read.csv("./data/pml-training.csv")
inTrain <- createDataPartition(y=pml_data$classe, list=FALSE, p=0.7)
training <- pml_data[inTrain,]
testing <- pml_data[-inTrain,]
validation <- read.csv("./data/pml-testing.csv")
setwd("C:/Users/johnecon/Projects/datasciencecoursera/Practical Machine Learning/assignment/")
pml_data <- read.csv("./data/pml-training.csv")
inTrain <- createDataPartition(y=pml_data$classe, list=FALSE, p=0.7)
training <- pml_data[inTrain,]
testing <- pml_data[-inTrain,]
validation <- read.csv("./data/pml-testing.csv")
pml_data <- read.csv("./data/pml-training.csv", na.strings=c("NA","","#DIV/0!"))
inTrain <- createDataPartition(y=pml_data$classe, list=FALSE, p=0.7)
training <- pml_data[inTrain,]
testing <- pml_data[-inTrain,]
validation <- read.csv("./data/pml-testing.csv")
dim(training)
dim(testing)
head(training)
pml<-read.csv("./data/pml-training.csv")
head(ppml
)
head(pml)
View(pml)
View(pml)
dim(validation)
dim(testing)
colSums(is.na(training))/nrow(training)
is.na(training)
?colSums
?createDataPartition
pml_data$classe<-as.factor(pml_data$classe)
pml_data$classe
pml_data <- read.csv("./data/pml-training.csv", na.strings=c("", "NA","#DIV/0!"))
pml_data$classe
head(training)
names(training)
colSums(is.na(training)) == 0
colSums(is.na(trainData))/nrow(trainData)>0.7
colSums(is.na(training))/nrow(trainData)>0.7
colSums(is.na(training))/nrow(training)>0.7
t <- training[,colSums(is.na(training))/nrow(training)>0.7]
names(t)
colSums(is.na(t))/nrow(t)>0.7
training <- training[,colSums(is.na(training))/nrow(training)>0.7]
names(training)
inTrain <- createDataPartition(y=pml_data$classe, list=FALSE, p=0.7)
training <- pml_data[inTrain,]
testing <- pml_data[-inTrain,]
validation <- read.csv("./data/pml-testing.csv")
training <- training[,colSums(is.na(training))/nrow(training)<0.7]
names(training)
training <- training1[,-c(1:7)]
training <- training[,-c(1:7)]
names(training)
-nearZeroVar(train)
nearZeroVar(train)
nearZeroVar(training)
t<- training[,-nearZeroVar(training)]
names(t)
nearZeroVar(plm_data)
nearZeroVar(pml_data)
modFitRF <- train(classe ~ ., data = training, method = "rf")
modFitRF <- train(classe ~ ., data = training, method = "rf", prox=TRUE)
modFitRF <- train(classe ~ ., data = training, method = "rf", ntree=10)
predRF <- predict(modFitRF, testing)
confusionMatrix(predRF, testing$classe)
confusionMatrix(predRF, testing$classe)$overall[1]
predRF <- predict(modFitRF$finalModel, testing)
predRF <- predict(modFitRF$finalModel, newdata=testing)
predRF <- predict(modFitRF, testing)
predRF <- predict(modFitRF$finalModel, newdata = testing)
predRF <- predict(modFitRF, validation)
confusionMatrix(predRF, testing$classe)
confusionMatrix(predRF, validation$classe)
predRF <- predict(modFitRF, testing)
confusionMatrix(predRF, testing$classe)
predRF <- predict(modFitRF, validation)
confusionMatrix(predRF, validation$classe)
validation$classe
validation <- read.csv("./data/pml-testing.csv")
validation$classe
predRF <- predict(modFitRF, validation)
predRF
predRF <- predict(modFitRF, testing)
confusionMatrix(predRF, testing$classe)
predRF <- predict(modFitRF, testing)
confusionMatrix(predRF, testing$classe)
predRF <- predict(modFitRF, testing)
confusionMatrix(predRF, testing$classe)
predRF <- predict(modFitRF, testing)
confusionMatrix(predRF, testing$classe)
dim(training)
confusionMatrix(predRF, testing$classe)$overall[0]
confusionMatrix(predRF, testing$classe)$overall[1]
modFitRF <- train(classe ~ ., data = training, method = "rf", ntree=20)
predRF <- predict(modFitRF, testing)
confusionMatrix(predRF, testing$classe)
# Accuracy
confusionMatrix(predRF, testing$classe)$overall[1]
modFitRF$finalModel
modFitRF <- train(classe ~ ., data = training, method = "rf", ntree=10)
modFitRF20 <- train(classe ~ ., data = training, method = "rf", ntree=10)
modFitRFCV <- train(classe ~ ., data = training, method = "rf", ntree=10, trainControl=tr)
tr <- trainControl(method = "cv",number = 10)
modFitRFCV <- train(classe ~ ., data = training, method = "rf", ntree=10, trainControl=tr)
predRF <- predict(modFitRF, testing)
confusionMatrix(predRF, testing$classe)
predRF20 <- predict(modFitRF20, testing)
confusionMatrix(predRF20, testing$classe)
predRFCV <- predict(modFitRFCV, testing)
confusionMatrix(predRFCV, testing$classe)
predRF$finalModel
predRF
modFitRF$finalModel
modFitRFCV$finalModel
modFitRF20$finalModel
modFitRF20 <- train(classe ~ ., data = training, method = "rf", ntree=20)
predRF20 <- predict(modFitRF20, testing)
confusionMatrix(predRF20, testing$classe)
tr <- trainControl(method = "cv",number = 20)
modFitRFCV <- train(classe ~ ., data = training, method = "rf", ntree=20, trainControl=tr)
predRFCV <- predict(modFitRFCV, testing)
confusionMatrix(predRFCV, testing$classe)
predRF <- predict(modFitRF20$finalModel, validation)
predRF <- predict(modFitRF20, validation)
modFitRF20
modFitRF20
modFitRF20
final_pred
predict(mod_fit_rf_20$finalModel, validation)
mod_fit_rf_20 <- train(classe ~ ., data = training, method = "rf", ntree=20)
pred_rf_20 <- predict(mod_fit_rf_20, testing)
confusionMatrix(pred_rf_20, testing$classe)
mod_fit_glm <- train(classe ~ ., data = training, method = "glm")
print(mod_fit_rf_20$finalModel)
plot(mod_fit_rf_20$finalModel, uniform=TRUE, main="Classification Tree")
text(mod_fit_rf_20$finalModel, use.n=TRUE, all=TRUE, cex=.8)
library(ggplot2)
print(mod_fit_rf_20$finalModel)
plot(mod_fit_rf_20$finalModel, uniform=TRUE, main="Classification Tree")
text(mod_fit_rf_20$finalModel, use.n=TRUE, all=TRUE, cex=.8)
print(mod_fit_rf_20$finalModel)
library(rattle)
fancyRpartPlot(mod_fit_rf_20$finalModel)
print(mod_fit_rf_20$finalModel)
print(modFitRF$finalModel)
print(modFitRFCV$finalModel)
tr <- trainControl(method = "cv",number = 5)
mod_fit_rf_20 <- train(classe ~ ., data = training, method = "rf", ntree=10 , trainControl=tr, prox=TRUE,allowParallel=TRUE)
mod_fit_rf_20 <- train(classe ~ ., data = training, method = "rf", ntree=10 , trainControl=tr,allowParallel=TRUE)
mod_fit_rf_20 <- train(classe ~ ., data = training, method = "rf", ntree=10 , trainControl=tr)
mod_fit_rf_20 <- train(classe ~ ., data = training, method = "rf", ntree=10)
print(mod_fit_rf_20)
print(mod_fit_rf_20$finalModel)
plot(mod_fit_rf_20$finalModel, uniform=TRUE, main="Classification Tree")
text(mod_fit_rf_20$finalModel, use.n=TRUE, all=TRUE, cex=.8)
plot(mod_fit_rf_20$finalModel, main="Classification Tree")
tr <- trainControl(method = "cv",number = 5)
mod_fit_cv <- train(classe ~ ., data = training, method = "rf", ntree=10 , trainControl=tr)
pred_rf_cv <- predict(mod_fit_cv, testing)
confusionMatrix(pred_rf_cv, testing$classe)
tr <- trainControl(method = "cv",number = 5)
mod_fit_cv <- train(classe ~ ., data = training, method = "rf", ntree=15, trainControl=tr)
pred_rf_cv <- predict(mod_fit_cv, testing)
confusionMatrix(pred_rf_cv, testing$classe)
pred_rf_15 <- predict(mod_fit_rf_20, testing)
confusionMatrix(pred_rf_15, testing$classe)
pred_rf_15 <- predict(mod_fit_rf_15, testing)
confusionMatrix(pred_rf_15, testing$classe)
pred_rf_15 <- predict(mod_fit_rf_15, testing)
mod_fit_rf_15 <- train(classe ~ ., data = training, method = "rf", ntree=15)
pred_rf_15 <- predict(mod_fit_rf_15, testing)
confusionMatrix(pred_rf_15, testing$classe)
pred_rf_20 <- predict(mod_fit_rf_15, testing)
confusionMatrix(pred_rf_20, testing$classe)
pred_rf_20 <- predict(mod_fit_rf_20, testing)
confusionMatrix(pred_rf_20, testing$classe)
mod_fit_rf_15 <- train(classe ~ ., data = training, method = "rf", ntree=15)
pred_rf_15 <- predict(mod_fit_rf_15, testing)
confusionMatrix(pred_rf_15, testing$classe)
pred_rf_cv <- predict(mod_fit_cv, testing)
confusionMatrix(pred_rf_cv, testing$classe)
predict(mod_fit_rf_15$finalModel, validation)
predict(mod_fit_rf_15, validation)
